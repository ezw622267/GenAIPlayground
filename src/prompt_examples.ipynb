{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a46ac56",
   "metadata": {},
   "source": [
    "## Prompt Engineering Playground\n",
    "\n",
    "#### This notebook contains examples of how to effectively use prompting strategies in code, as well as what to look out for. We will be using Ollama as the LLM. \n",
    "\n",
    "#### Important tips\n",
    "     1) LLM outputs have no built-in mechanism for output verification - be skeptical! \n",
    "     2) LLMs are *not* replacements for sound software principles and algorithmic analysis. \n",
    "     3) LLMs are great for assisting in code documentation, but use the outputs as templates and rought drafts\n",
    "     4) The distinction between prompt strategies is not always clear-cut, many overlap and/or build off others.\n",
    "\n",
    "#### Prompt strategies\n",
    "     1) I/O prompting\n",
    "     2) Prompt templating & chaining\n",
    "     3) Few-shot prompting\n",
    "     4) Retrieval-Augmented Generation (RAG)\n",
    "     5) Chain-of-Thought (CoT)\n",
    "     6) Automated Prompt Engineering (APE) & Meta-prompting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd78fd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\622267\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\622267\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ollama) (2.11.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27->ollama) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.9->ollama) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\622267\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.3.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\622267\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\622267\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\622267\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\622267\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install ollama\n",
    "!pip install scikit-learn\n",
    "!pip install torch\n",
    "!pip install transformers \n",
    "#!pip install huggingface-hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aafe3bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down what Large Language Models (LLMs) are. \n",
      "\n",
      "**What are LLMs?**\n",
      "\n",
      "Imagine a computer program that can hold and understand human language in a way similar to how we do.  That's essentially the core idea behind LLMs! These powerful AI systems, built on deep learning, are trained on massive datasets of text (think books, articles, code). \n",
      "\n",
      "**How Do LLMs Work?**\n",
      "\n",
      "1. **Data is King:** LLMs learn by analyzing enormous amounts of text data. This process helps them develop a vast understanding of language structure, grammar, and meaning.\n",
      "2. **Transformers at the Helm:** A key component in many LLMs is the \"Transformer\" architecture.  It excels at processing sequences like words or sentences (think sentence-level analysis) and capturing relationships between these elements. \n",
      "3. **Predicting the Next Word:**  LLMs are essentially sophisticated predictive models. They analyze a given text sequence and try to predict the most probable next word based on what has come before. By repeating this step, they can generate coherent and contextually relevant text, whether it's an email, a poem, or even code.\n",
      "\n",
      "**Types of LLMs**\n",
      "\n",
      "* **GPT (Generative Pre-trained Transformer):**  Known for its ability to create human-like text. It powers chatbots like ChatGPT and has been used for tasks like writing summaries, generating creative content, and translating languages.\n",
      "* **LaMDA (Language Model for Dialogue Applications):** Focused on dialogue generation. Designed to engage in natural, open-ended conversations with humans. \n",
      "* **PaLM (Pathway Language Model):**  A massive model trained by Google. It excels at a wide range of language tasks, including code generation, math problem solving, and even reasoning.\n",
      "\n",
      "\n",
      "**What Can LLMs Do?**\n",
      "\n",
      "LLMs are incredibly versatile! Here's just a glimpse:\n",
      "\n",
      "* **Text Generation:** Writing stories, poems, articles, or summaries.\n",
      "* **Language Translation:** Converting text from one language to another.\n",
      "* **Chatbots and Virtual Assistants:** Providing conversational responses and completing tasks.\n",
      "* **Code Generation:** Creating code in different programming languages based on instructions.\n",
      "* **Summarization:**  Condensing large texts into concise summaries. \n",
      "* **Question Answering:** Finding answers to questions based on provided text. \n",
      "\n",
      "**The Future of LLMs**\n",
      "\n",
      "\n",
      "LLMs are rapidly evolving, and the potential impact is huge! We're seeing their integration in various applications: \n",
      "\n",
      "* **Personalized Learning:** Tailored educational experiences for students.\n",
      "* **Content Creation Tools:**  Automating writing tasks and enhancing creativity. \n",
      "* **Customer Service Automation:** Intelligent chatbots to handle customer queries effectively.\n",
      "* **Medical Diagnostics:** Analyzing patient data to assist doctors with diagnosis.\n",
      "\n",
      "\n",
      "**Keep in mind:**\n",
      "\n",
      "* LLMs are not perfect! They can sometimes generate inaccurate or nonsensical outputs, and they still struggle with complex reasoning tasks. \n",
      "* Ethical considerations around bias, privacy, and misuse of powerful AI systems need careful attention.  \n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have more questions or want to delve into a specific aspect of LLMs in detail!\n"
     ]
    }
   ],
   "source": [
    "#Downloading Ollama\n",
    "import os \n",
    "import ollama\n",
    "\n",
    "ollama.list() #lists available ollama models\n",
    "ollama.pull(\"gemma2:2b\") #we will use the lightweight gemma2 with 2B parameters for this notebook\n",
    "response = ollama.generate(model = 'gemma2:2b',\n",
    "                           prompt = 'explain LLMs')\n",
    "\n",
    "print(response['response'])\n",
    "\n",
    "#This cell should take between 4 - 5 min to run on a CPU (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038db3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def min_array(arr):\n",
      "  \"\"\"\n",
      "  Finds the minimum value in an array.\n",
      "\n",
      "  Args:\n",
      "    arr: The array to find the minimum of.\n",
      "\n",
      "  Returns:\n",
      "    The minimum value in the array. \n",
      "  \"\"\"\n",
      "\n",
      "  if not arr:\n",
      "    return None  # Return None if the array is empty\n",
      "\n",
      "  min_value = arr[0]  # Initialize min_value with the first element\n",
      "  for value in arr:\n",
      "    if value < min_value:\n",
      "      min_value = value \n",
      "  return min_value\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. **Function Definition (`def min_array(arr):`)**: This defines a function named `min_array` that takes one argument, `arr`, which represents the array we want to examine.\n",
      "\n",
      "2. **Empty Array Check (`if not arr: return None`)**:  It checks if the array is empty using `not arr`. If it's empty, it returns `None` to avoid errors. This makes the code more robust. \n",
      "\n",
      "3. **Initialization (`min_value = arr[0]`)**: The code initializes a variable `min_value` with the value of the first element in the array using `arr[0]`.  \n",
      "\n",
      "4. **Iterating through the Array (`for value in arr:`)**: This loop goes through each element (`value`) within the provided array:\n",
      "   * **Comparison (`if value < min_value:`)**: For each element, it compares it to the current `min_value` and updates `min_value` if a smaller element is found. \n",
      "\n",
      "5. **Returning the Minimum Value (`return min_value`)**: After checking all elements,  the function returns the final `min_value`, which now holds the minimum value in the array.\n",
      "\n",
      "\n",
      "**Example Usage:**\n",
      "\n",
      "```python\n",
      "numbers = [4, 2, 7, 1, 9] \n",
      "minimum = min_array(numbers)\n",
      "print(f\"The minimum value is: {minimum}\")  # Output: The minimum value is: 1\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have any other questions about this function or need help with further array-related tasks in Python!\n"
     ]
    }
   ],
   "source": [
    "#I/O prompt\n",
    "\n",
    "#### This is the simplest case - you simply ask the LLM to complete a task and record the output. \n",
    "#### NOT SUITABLE for complex use cases (otherwise, we wouldn't bother with prompt engineering)\n",
    "\n",
    "prompt = \"write me a python function to find the minimum of an array\"\n",
    "\n",
    "llm_output = ollama.generate(model = 'gemma2:2b',\n",
    "                             prompt = prompt)['response'] #this will output the code snippet\n",
    "\n",
    "print(llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a071956e",
   "metadata": {},
   "source": [
    "##### Check - is the program valid? Have you checked your inputs into the function? Is there a more efficient way to write the piece of code? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt templating & chaining\n",
    "\n",
    "#### Prompt template - rather than having a fixed string, you format it with some other value(s) before passing to an LLM. This can take many forms but here is one for reference\n",
    "character = \"Spongebob\"\n",
    "template = f\"Explain in one sentence who {character} is\"\n",
    "llm_output = ollama.generate(model = 'gemma2:2b',\n",
    "                             prompt = template)\n",
    "\n",
    "## Prompt chaining -   input -> LLM -> output -> LLM -> output -+ ... \n",
    "### Prompt chaining is where you break down your problem into simpler tasks and chain together the outputs to solve the overall larger goal. \n",
    "### Note that we can combine multiple templated prompts into a prompt chain \n",
    "\n",
    "project_description = 'custom memory allocator'\n",
    "prompt_1 = 'explain the tradeoffs when using the GCC compiler for C++ vs. Clang'\n",
    "\n",
    "\n",
    "compiler_tradeoffs = ollama.generate(model = 'gemma2:2b',\n",
    "                                     prompt = prompt_1)['response'] #get the compiler tradeoffs description \n",
    "\n",
    "prompt_2 = f\"\"\"Write me a recommendation for which compiler to use for my C++ project: {project_description},\n",
    " considering the differences between Clang and GCC explained here: {compiler_tradeoffs}\"\"\" \n",
    "\n",
    "\n",
    "recommendation = ollama.generate(model = 'gemma2:2b',\n",
    "                                 prompt = prompt_2)['response']\n",
    "\n",
    "\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d54770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want you to classify text into positive, negative, or netural sentiment. \n",
      "Please output only the sentiment. Examples are below:\n",
      "This is great! : positive\n",
      "This is terrible! : negative\n",
      "This is just okay : neutral\n"
     ]
    }
   ],
   "source": [
    "##Few-shot prompting\n",
    "\n",
    "#### Few-shot prompting is where we provide several curated examples in addition to a prompt as context.\n",
    "\n",
    "examples = [(\"This is great!\",\"positive\"),(\"This is terrible!\",\"negative\"),(\"This is just okay\",\"neutral\")]\n",
    "formatted_examples = '\\n'.join(['{} : {}'.format(examples[i][0],examples[i][1]) for i in range(len(examples))])\n",
    "\n",
    "prompt = f\"\"\"I want you to classify text into positive, negative, or netural sentiment. \n",
    "Please output only the sentiment. Examples are below:\\n{formatted_examples}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "ollama.generate(model = 'gemma2:2b',\n",
    "                prompt = prompt)['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb2b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
